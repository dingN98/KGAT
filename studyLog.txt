2022.5.18
不知道为啥，commit的文件只要达到几十M，就会push失败，所以我只push了代码，没有push数据。

论文速看：

KGAT模型主要由三个部分组成:
1)嵌入层，通过保留CKG的结构，将每个节点参数化为一个向量;
2)注意嵌入传播层，递归地传播来自节点邻居的嵌入，更新节点表示，并在传播过程中利用知识感知的注意机制学习每个邻居的权值;
3)预测层，将来自所有传播层的用户和项的表示集合起来，输出预测的匹配分数。

【嵌入层】使用【TransR】模型将【实体】和【关系】向量化
【注意嵌入传播层】 权重的计算、tail乘以权重（结果记作A)、head和A的聚合、多跳、多跳的聚合
【预测层】将user的多跳聚合结果 和 item的多跳聚合结果 内积，作为向user推荐item的分数

明天看代码。
ps:今天跑了2公里，用了11分半。

2022.5.19
和龙王谈了下，他在华为南研所上班，一年30万以上（含年终奖10万），会加班。在牛首山附近（云望府），2.79万一平。租房一年五万，和女朋友住一起。
和老姐谈了下，江苏银行技术岗，会加班到晚上八九点，年薪不及华为，但是更加稳定。姐夫刚毕业也没有几十万，其他途径涨到这么高（七十万以上）。

关于今天的小论文，看代码，看他是：
1、怎么构建联合知识图谱CKG
2、那几个公式、模型的构建
3、怎么和基线比较性能

只能下午开始了，上午都在聊天。

一个执行命令
python Main.py --model_type kgat --alg_type bi --dataset last-fm --regs [1e-5,1e-5] --layer_size [64,32,16] --embed_size 64 --lr 0.0001 --epoch 1000 --verbose 50 --save_flag 1 --pretrain -1 --batch_size 1024 --node_dropout [0.1] --mess_dropout [0.1,0.1,0.1] --use_att True --use_kge True
预计跑完1000个epoch，需要2.7天

Main.py

1、首先是加载数据集 load_data.py
（1）得到训练集和测试集  self._load_ratings()
self.train_data, self.train_user_dict = self._load_ratings(train_file)     train_file = path + '/train.txt'
train.txt  每一行是 【userid,item1,itme2,...】   train_data 是一个矩阵，每一行是【userid,itemid】  train_user_dict 是一个dict()，key是userID,value是这个user交互的items【item1，item2，...】
self.test_data, self.test_user_dict = self._load_ratings(test_file)  类似
（2）得到知识图谱相关数据 self._load_kg()
kg_dict  是一个字典  kg[head].append((tail, relation))
relation_dict   是一个字典  rd[relation].append((head, tail))
（3）生成 batch_size 大小的正样品和负样品  _generate_train_cf_batch()
return users, pos_items, neg_items
其中，users 是 batch_size 大小的[]
pos_items 是 batch_size * num 的矩阵， 是指 train_user_dict 里面涉及到的数据
neg_items 是 train_user_dict 里面没提到的数据

KGAT.py


1、参数转换 def _parse_args(self, data_config, pretrain_data, args)
首先获取 n_users n_items n_entities n_relations
然后是其他数据   来自   loader_kgat.py
（1）根据 user-item 交互数据 生成 稀疏的邻接矩阵

# generate the sparse adjacency matrices for user-item interaction & relational kg data.
self.adj_list, self.adj_r_list = self._get_relational_adj_list()



Epoch 0 [261.7s]: train==[789.20233=39.57340 + 749.46057 + 0.16889]
[n_users, n_items]=[23566, 48123]
[n_train, n_test]=[1289003, 423635]
[n_entities, n_relations, n_triples]=[106389, 9, 464567]
[batch_size, batch_size_kg]=[1024, 369]
[n_users, n_items]=[23566, 48123]
[n_train, n_test]=[1289003, 423635]
[n_entities, n_relations, n_triples]=[106389, 9, 464567]
[batch_size, batch_size_kg]=[1024, 369]
        convert ratings into adj mat done.
        convert ratings into adj mat done.
[n_users, n_items]=[23566, 48123]
[n_train, n_test]=[1289003, 423635]
[n_entities, n_relations, n_triples]=[106389, 9, 464567]
[batch_size, batch_size_kg]=[1024, 369]
[n_users, n_items]=[23566, 48123]
[n_train, n_test]=[1289003, 423635]
[n_entities, n_relations, n_triples]=[106389, 9, 464567]
[batch_size, batch_size_kg]=[1024, 369]
[n_users, n_items]=[23566, 48123]
[n_train, n_test]=[1289003, 423635]
[n_entities, n_relations, n_triples]=[106389, 9, 464567]
[batch_size, batch_size_kg]=[1024, 369]
        convert 20 relational triples into adj mat done. @0.4528s
        convert 20 relational triples into adj mat done. @0.4299s

2022.5.20 玩
2022.5.21 玩
2022.5.22
继续干活儿
上回解析了Main.py里的主要逻辑：
生成训练集、测试集、知识图谱相关数据、batch_size大小的正样品和负样品

在研究 KGAT.py之前，需要研究 loader_kgat.py  它为KGAT.py提供数据来源

loader_kgat.py   做的准备工作如下：

# generate the sparse adjacency matrices for user-item interaction & relational kg data.
# 生成稀疏的邻接矩阵（user-item交互矩阵、KG关系），adj_list 包含所有的user-item的交互矩阵  还有逆矩阵，adj_r_list 包含所有的  关系id
# 用稀疏矩阵变量adj_mat_list存储CF与KG的连通信息。
self.adj_list, self.adj_r_list = self._get_relational_adj_list()

# generate the sparse laplacian matrices.
# 生成稀疏的拉普拉斯矩阵，主要是上一步得到的稀疏CF及KG连通矩阵进行归一化操作。
# 这里重点说一下为啥需要归一化：原始的连通矩阵是没有归一化的，如果没有归一化的连通矩阵与特征矩阵相乘会改变特征的原本分布，产生一些不可预测的问题，所以需要对连通矩阵进行标准化处理。
self.lap_list = self._get_relational_lap_list()

# generate the triples dictionary, key is 'head', value is '(tail, relation)'.
# 生成三元组字典： all_kg_dict[head].append((tail, relation))
self.all_kg_dict = self._get_all_kg_dict()

# 获取所有的 head列表，relation列表、tail列表，data列表
self.all_h_list, self.all_r_list, self.all_t_list, self.all_v_list = self._get_all_kg_data()

接着研究核心代码 KGAT.py

# 解析参数，包含 n_users、n_items、若干邻接矩阵 等等
self._parse_args(data_config, pretrain_data, args)

# Create Placeholder for Input Data & Dropout.
self._build_inputs()

# Create Model Parameters for CF & KGE parts.
# 构建所有的权重  all_weights = dict()  如果存在预训练数据，那么使用，否则使用 xavier 初始化随机数据
# 权重包括：用户嵌入 user_embed 【n_users * emb_dim】实体嵌入 entity_embed 【n_entities * emb_dim】 物品嵌入 item_embed 关系嵌入  relation_embed
# ??? trans_W   tf.Variable(initializer([self.n_relations, self.emb_dim, self.kge_dim]))   ??? 这里需要研究下
# ??? gc、bi、mlp三层是啥???
# 执行命令 python Main.py 里有一个参数  --layer_size [64,32,16]
而 self.weight_size = eval(args.layer_size)   self.n_layers = len(self.weight_size)  这里的layer_size  就是 3
# 然后遍历这三层layer，继续往 all_weights 里加入参数  三层  gc bi mlp
# 三层 W 其实对应着  emb_dim * 64 、 64*32 、(2*32) * 16
# 三层 b 对应着 1*64、1*32、1*16
self.weights = self._build_weights()



2022.5.23
今天白天都在和 htw 一起搞服务器，成功装到机架上了，但是还是IP有问题。
晚上继续学习小论文代码！！！

# Compute Graph-based Representations of All Users & Items & KG Entities via Message-Passing Mechanism of Graph Neural Networks.
# 使用不同的卷积层，通过KG的消息传递机制，计算所有的 user、item、entity的 表示
# Different Convolutional Layers: bi  、 gcn 、 graphsage  这其实是 当前实体的信息 和 邻域实体 信息聚合的三种方式
# python Main.py --model_type kgat --alg_type bi  可见论文作者默认使用 bi 卷积层，因为从论文的实验结果来看，bi聚合器的 指标最好
# 三个核心函数的核心不同点代码
# 1、 _create_bi_interaction_embed()    fBi-Interaction =LeakyReLU?W1(eh + eNh )?+ LeakyReLU?W2(eh ⊙ eNh )?,
# add_embeddings = ego_embeddings + side_embeddings
# bi_embeddings = tf.multiply(ego_embeddings, side_embeddings)
# 2、_create_gcn_embed()    fGCN = LeakyReLU?W(eh + eNh )?
# embeddings = tf.concat(temp_embed, 0)
# 3、_create_graphsage_embed()     fGraphSage = LeakyReLU?W(eh ||eNh )?
#  embeddings = tf.concat([pre_embeddings, embeddings], 1)
self._build_model_phase_I()

# Optimize Recommendation (CF) Part via BPR Loss.
# 对应论文 3.4 节  LCF =X(u,i, j)∈ O− ln σ ? ˆy(u, i) − ˆy(u, j)?
self._build_loss_phase_I()

# Compute Knowledge Graph Embeddings via TransR.
# 计算 实体的 TransR 嵌入
self._build_model_phase_II()

# Optimize KGE Part via BPR Loss.
# 优化 KGE 的损失函数
self._build_loss_phase_II()

# 打印静态参数
self._statistics_params()

重点来了！！！
Main.py 继续 Train
是否使用 KGE 模型 和 是否使用注意力机制  是可以调节的！
264行    if args.use_kge is True:
278行    if args.use_att is True:

for epoch in range(args.epoch):
    phase 1: to train the recommender.
    phase 2: to train the KGE method & update the attentive Laplacian matrix.
    Test.
    Performance logging.

明天继续！

2022.5.24
白天在搞解决 HDFS 的 bug，晚上继续搞论文

首先要搞明白
1、是不是一定要用KGE模型
（1）这个KGE需要的训练数据怎么生成?
loader_kgat.py  里面的 _generate_train_A_batch()方法
heads, relations, pos_tails, neg_tails = self._generate_train_A_batch()

需要知道这个方法是怎么生成 batch_size 大小的训练数据的
首先，需要知道 all_kg_dict 里记录了所有的知识图谱三元组  all_kg_dict[head].append((tail, relation))
然后，这个 all_kg_dict 里出现的三元组 (h,r,t) 是 pos训练数据， 里面没出现的是 neg训练数据
怎么从 all_kg_dict 里获取这两种数据？ 对于 pos数据，直接从 all_kg_dict 随机选取 batch_size 大小的 数据即可，即为 heads, relations, pos_tails
然后对于每一个 header ，随机生成一个 不在 all_dict[header] 里出现过得 tail，就是 neg_tail  然后最后得到  neg_tails

（2）怎么训练KGE
首先将 self._generate_train_A_batch() 生成的数据构造成 feed_dict 的字典格式
feed_dict = {
            model.h: batch_data['heads'],
            model.r: batch_data['relations'],
            model.pos_t: batch_data['pos_tails'],
            model.neg_t: batch_data['neg_tails'],

        }
注意，这里的例如 model.h  会覆盖 例如model是KGAT里定义的  self.h
然后就是，这里的 self.h 只是 KG 里 head 节点的 id
定义的 self.h_e  才是 h 的 嵌入，初始的嵌入是 随机生成的，二者通过下面这个函数建立关系：
self.h_e, self.r_e, self.pos_t_e, self.neg_t_e = self._get_kg_inference(self.h, self.r, self.pos_t, self.neg_t)
以 head 为例   h_e = tf.nn.embedding_lookup(embeddings, h)   一开始 h 对应的 h_e  是随机生成的

然后才是训练
_, batch_loss, batch_kge_loss, batch_reg_loss = model.train_A(sess, feed_dict=feed_dict)
train_A() 的具体工作
sess.run([self.opt2, self.loss2, self.kge_loss2, self.reg_loss2], feed_dict)
和论文里公式相对应的代码部分如下：
kg_score = tf.reduce_sum(tf.square((h_e + r_e - t_e)), 1, keepdims=True)
kg_loss = tf.reduce_mean(tf.nn.softplus(-(neg_kg_score - pos_kg_score)))

其实，TransR模型的训练，需要将 h 和 t 映射到 r 的维度，然后再执行 h+r-t 这种。好像论文作者为了简化计算，设置的 h、r、t 的维度都是 64      --embed_size 64
不对，在 _get_kg_inference(self, h, r, pos_t, neg_t) 这个函数里，有这个
self.weights['trans_W']
感觉就是 h 到 r 的维度转换矩阵，这个问题留给明天研究。

（3）终于到了最终问题，要不要使用KGE模型
我觉得要解决这个问题，得先解决下一个问题。就是本文作者除了使用了KGE，还使用了基于注意力机制的信息传播和信息聚合，这个东西的作用是啥？如果只用这个，不用KGE的影响。


2、是不是一定要用注意力机制
基于 user-item-rate 做的训练
feed_dict = {
            model.users: batch_data['users'],
            model.pos_items: batch_data['pos_items'],
            model.neg_items: batch_data['neg_items'],

            model.mess_dropout: eval(self.args.mess_dropout),
            model.node_dropout: eval(self.args.node_dropout),
        }
_, batch_loss, batch_base_loss, batch_kge_loss, batch_reg_loss = model.train(sess, feed_dict=feed_dict)

loss计算公式
pos_scores = tf.reduce_sum(tf.multiply(self.u_e, self.pos_i_e), axis=1)
neg_scores = tf.reduce_sum(tf.multiply(self.u_e, self.neg_i_e), axis=1)
base_loss = tf.reduce_mean(tf.nn.softplus(-(pos_scores - neg_scores)))

我感觉 利用 用户的rating 来训练 ，也是在训练 u_e 和 pos_i_e  等这种嵌入，使得 u_e 和 pos_ie 的乘积之和 尽可能大。
因此和 KGE （训练 h_e 、 r_e 、 t_e）的区别是啥呢？
这个问题留给明天解决吧。。。

2022.5.25
要解决俩遗留问题
1、注意力机制的问题
论文里实体 h 和它的邻域实体 t 之间的有一个注意力系数 π，公式为 π(h, r, t) = (Wr et )⊤tanh?(Wr eh + er )?
需要先找到这个公式对应着代码的哪个位置。。。

我先理解 本实体的信息和邻域实体的信息聚合问题
以 bi 方式做信息聚合为例： 主要涉及到 （1）邻域信息的确立 （2）+聚合方式   （3）乘法聚合方式
（1）领域信息的确立
# sum messages of neighbors.
side_embeddings = tf.concat(temp_embed, 0)
（2）+聚合方式
# sum messages of neighbors.
add_embeddings = ego_embeddings + side_embeddings
# transformed sum messages of neighbors.
sum_embeddings = tf.nn.leaky_relu(tf.matmul(add_embeddings, self.weights['W_gc_%d' % k]) + self.weights['b_gc_%d' % k])
（3）乘法聚合方式
# bi messages of neighbors.
bi_embeddings = tf.multiply(ego_embeddings, side_embeddings)
# transformed bi messages of neighbors.
bi_embeddings = tf.nn.leaky_relu(tf.matmul(bi_embeddings, self.weights['W_bi_%d' % k]) + self.weights['b_bi_%d' % k])
（4）将以上两种聚合方式的结果相加，在做 dropout 和 正则化
ego_embeddings = bi_embeddings + sum_embeddings
ego_embeddings = tf.nn.dropout(ego_embeddings, 1 - self.mess_dropout[k])
norm_embeddings = tf.math.l2_normalize(ego_embeddings, axis=1)
（5）再将结果加入[]  以便实现论文里的多层传播后的嵌入的拼接（在第一个维度的拼接）
all_embeddings += [norm_embeddings]
all_embeddings = tf.concat(all_embeddings, 1)

然后找到在哪里体现了邻域实体信息的计算
self.A_in
论文里是这样写的：
Knowledge-aware Attention:
We implement π(h, r, t) via relational attention mechanism, which is formulated as follows:
π(h, r, t) = (Wr et )⊤tanh?(Wr eh + er )?

在代码里，
model.update_attentive_A(sess)  会更新 self.A_in

然后就是 邻域实体的信息 和 注意力系数 相乘
论文里是    eNh =X(h,r,t)∈Nh π(h, r, t)et
对应着代码里以下几行：
A = self.A_in
A_fold_hat = self._split_A_hat(A)
temp_embed = []
for f in range(self.n_fold):
      temp_embed.append(tf.sparse_tensor_dense_matmul(A_fold_hat[f], ego_embeddings))
这个 temp_embed 就是聚合后的邻域实体信息list


2、高阶连通性问题
就是 n 层的传播，作者实验得出3层最佳。需要将这 n 层的嵌入拼接起来  e∗u = e(0)u ∥· · · ∥e(L)u , e∗i = e(0)i ∥· · · ∥e(L)i
对应的代码在 例如函数 _create_graphsage_embed(self)   中的
all_embeddings = [pre_embeddings]
all_embeddings += [norm_embeddings]
all_embeddings = tf.concat(all_embeddings, 1)
ua_embeddings, ea_embeddings = tf.split(all_embeddings, [self.n_users, self.n_entities], 0)


2022.5.26

1、KGE的权重问题  self.weights['trans_W']

首先考虑各种实体嵌入的维度
user_embed ： [self.n_users, self.emb_dim]
entity_embed：  [self.n_entities, self.emb_dim]
relation_embed: [self.n_relations, self.kge_dim]

然后是 KGE 权重的维度，目的是将 h 和 t 所在的空间映射到 r 所在的空间
trans_W: [self.n_relations, self.emb_dim, self.kge_dim]

对应的 h-r-t 的公式为：
д(h, r, t) = ??Wr eh + er − Wr et ??22
解读： 对于一组三元组(h,r,t) ， h 和 t 和 trans_W 相乘后 ，维度将从 [1,emb_dim] 变成 [1,kge_dim] ，就和 r 的维度一样了。

2、user-item 的权重问题  A_in
论文里对应的是：
π(h, r, t) = (Wr et )⊤tanh?(Wr eh + er )?
代码里
Main.py    config['A_in'] = sum(data_generator.lap_list)
loader_kgat.py   self.lap_list = self._get_relational_lap_list()
if self.args.adj_type == 'bi':
    lap_list = [_bi_norm_lap(adj) for adj in self.adj_list]
对应着执行语句  python Main.py --model_type kgat --alg_type bi
接着搞懂俩东西：
（1）self.adj_list
出自 loader_kgat.py
# generate the sparse adjacency matrices for user-item interaction & relational kg data.
self.adj_list, self.adj_r_list = self._get_relational_adj_list()


（2）_bi_norm_lap()  双归一化过程
说实话，这个函数我完全看不懂
感觉这篇论文的代码实现很复杂。感觉写了很多冗余的东西（这些东西论文里没有提到）

config['A_in'] = sum(data_generator.lap_list)
我试图寻找其他突破口  A_out  A_in
self.A_out = self._create_attentive_A_out()
new_A = sess.run(self.A_out, feed_dict={self.A_values: kg_score})
new_A_values = new_A.values
new_A_indices = new_A.indices
self.A_in = sp.coo_matrix((new_A_values, (rows, cols)), shape=(self.n_users + self.n_entities,self.n_users + self.n_entities))

上网查找提示如下：
def _get_relational_adj_list(self):     用稀疏矩阵变量adj_mat_list存储CF与KG的连通信息。
def _get_relational_lap_list(self):     将上一步得到的稀疏CF及KG连通矩阵进行归一化操作。
然后开始梳理脉络：
self.adj_list, self.adj_r_list = self._get_relational_adj_list()
# adj_list的作用是得到 lap_list ，然后就没用了
self.lap_list = self._get_relational_lap_list()
# lap_list的作用的得到 A_in
config['A_in'] = sum(data_generator.lap_list)
# 在 _create_bi_interaction_embed(self) 中，A_in的作用如下
A = self.A_in
A_fold_hat = self._split_A_hat(A)
temp_embed.append(tf.sparse_tensor_dense_matmul(A_fold_hat[f], ego_embeddings))
# temp_embed 就是 h 的邻域实体的乘上注意力机制后的 嵌入
side_embeddings = tf.concat(temp_embed, 0)
# 上面这步和论文里的 公式(3) 对应起来了

综上，这篇论文里，我觉得比较复杂的是三种权重
（1）KGE的权重  self.weights['trans_W']  用于将 h 和 t 映射到 r 所在的空间
（2）邻域实体的信息聚合涉及到的注意力机制  A_in
（3）最后是邻域实体的信息和实体h的信息聚合时，采用的三种聚合方式对应的三种权重，即
self.weights['W_gc_%d' % k] + self.weights['b_gc_%d' % k])
self.weights['W_bi_%d' % k] + self.weights['b_bi_%d' % k]
self.weights['W_mlp_%d' % k] + self.weights['b_mlp_%d' % k]


